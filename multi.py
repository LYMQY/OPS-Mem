# Qwen3-8B åœ¨çº¿è°ƒç”¨æµ‹è¯•è„šæœ¬ - ä½¿ç”¨Few-Shotå­¦ä¹ è§£å†³çº¿æ€§è§„åˆ’é—®é¢˜ï¼ˆOR-Toolsï¼‰
import json
import re
import sys
import os
from openai import OpenAI, APITimeoutError
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed
from prompts.fewshot_prompt import Q2C
import time
import httpx
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
import multiprocessing
from multiprocessing import Manager
from tqdm import tqdm

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å…¨å±€é…ç½®
CHUNK_SIZE = 160  # æ¯ä¸ªè¿›ç¨‹å¤„ç†çš„é—®é¢˜æ•°é‡
PROCESS_MAX_WORKERS = min(multiprocessing.cpu_count() // 2, 4)  # è¿›ç¨‹æ•°ï¼ˆCPUæ ¸å¿ƒæ•°çš„ä¸€åŠï¼Œæœ€å¤§4ï¼‰
THREAD_MAX_WORKERS = 2  # æ¯ä¸ªè¿›ç¨‹å†…çš„çº¿ç¨‹æ•°ï¼ˆæ§åˆ¶APIå¹¶å‘ï¼‰

# å¸¦é‡è¯•å’Œè¶…æ—¶çš„APIè°ƒç”¨å‡½æ•°ï¼ˆçº¿ç¨‹å†…ä½¿ç”¨ï¼‰
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=5),
    retry=retry_if_exception_type((APITimeoutError, httpx.ReadTimeout))
)
def get_response(client, messages):
    """æ¯ä¸ªçº¿ç¨‹ä½¿ç”¨ç‹¬ç«‹è¿›ç¨‹çš„clientè°ƒç”¨API"""
    response = client.chat.completions.create(
        model="Qwen/Qwen3-8B",
        messages=messages,
        timeout=30  # 30ç§’è¶…æ—¶
    )
    return response.choices[0].message.content

def process_single_problem(problem, client):
    """å•ä¸ªé—®é¢˜å¤„ç†ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰ï¼šç”Ÿæˆä»£ç å¹¶è¿”å›ç»“æœå­—å…¸"""
    problem_index = problem['index']
    question = problem['question']
    answer = problem.get('answer')
    
    try:
        # ç”Ÿæˆæç¤ºè¯
        ortools_prompt = Q2C(question)
        
        # æ„é€ è¾“å…¥æ¶ˆæ¯
        input_text = [
            {'role': 'system', 'content': 'Please follow the given examples and use python code to solve the given question.'},
            {'role': 'user', 'content': ortools_prompt}
        ]
        
        # è°ƒç”¨æ¨¡å‹ç”Ÿæˆä»£ç 
        generated_text = get_response(client, input_text)
        
        # æå–ä»£ç å—
        code_match = re.search(r"```python(.*?)```", generated_text, re.DOTALL)
        if not code_match:
            print(f"è­¦å‘Š: é—®é¢˜ #{problem_index} æœªæ‰¾åˆ°æœ‰æ•ˆä»£ç å—")
            return {
                'index': problem_index,
                'question': question,
                'answer': answer,
                'error': 'æœªæ‰¾åˆ°æœ‰æ•ˆçš„Pythonä»£ç å—'
            }
        
        code = code_match.group(1).strip()
        return {
            'index': problem_index,
            'question': question,
            'answer': answer,
            'generated_code': code
        }
    
    except (APITimeoutError, httpx.ReadTimeout) as e:
        error_msg = f"APIè¶…æ—¶: {str(e)}"
        print(f"é”™è¯¯: é—®é¢˜ #{problem_index} - {error_msg}")
        return {
            'index': problem_index,
            'question': question,
            'answer': answer,
            'error': error_msg
        }
    
    except Exception as e:
        error_msg = str(e)
        print(f"é”™è¯¯: é—®é¢˜ #{problem_index} - {error_msg}")
        return {
            'index': problem_index,
            'question': question,
            'answer': answer,
            'error': error_msg
        }

def process_chunk(chunk, results):
    """å•ä¸ªè¿›ç¨‹çš„æ ¸å¿ƒé€»è¾‘ï¼šå¤„ç†100æ¡é—®é¢˜çš„chunkï¼ˆè¿›ç¨‹å†…å¤šçº¿ç¨‹ï¼‰"""
    chunk_first_idx = chunk[0]['index'] if chunk else "N/A"
    chunk_last_idx = chunk[-1]['index'] if chunk else "N/A"
    chunk_len = len(chunk)
    print(f"ğŸ“Œ è¿›ç¨‹å¯åŠ¨ï¼šå¤„ç†é—®é¢˜ {chunk_first_idx} - {chunk_last_idx}ï¼ˆå…± {len(chunk)} æ¡ï¼‰")
    
    # æ¯ä¸ªè¿›ç¨‹åˆå§‹åŒ–ç‹¬ç«‹çš„OpenAIå®¢æˆ·ç«¯
    client = OpenAI(
        api_key=os.getenv("SiliconFlow_API_KEY1"),
        base_url="https://api.siliconflow.cn/v1"
    )
    
    # è¿›ç¨‹å†…å¯åŠ¨å¤šçº¿ç¨‹å¤„ç†chunk
    with ThreadPoolExecutor(max_workers=THREAD_MAX_WORKERS) as thread_executor:
        # æäº¤çº¿ç¨‹ä»»åŠ¡
        futures = [
            thread_executor.submit(process_single_problem, problem, client)
            for problem in chunk
        ]
        
        # ç”¨tqdmè¿½è¸ªè¿›åº¦ï¼štotalä¸ºä»»åŠ¡æ€»æ•°ï¼Œdescä¸ºè¿›åº¦æ¡æè¿°
        with tqdm(total=chunk_len, desc=f"è¿›ç¨‹[{chunk_first_idx}-{chunk_last_idx}]", leave=True) as pbar:
            # æ”¶é›†çº¿ç¨‹ç»“æœ
            for future in as_completed(futures):
                result = future.result()
                results.append(result)  # Manager.listçº¿ç¨‹/è¿›ç¨‹å®‰å…¨
                pbar.update(1)  # æ¯å®Œæˆä¸€ä¸ªä»»åŠ¡ï¼Œè¿›åº¦æ¡+1
    
    print(f"âœ… è¿›ç¨‹å®Œæˆï¼šé—®é¢˜ {chunk_first_idx} - {chunk_last_idx} å¤„ç†å®Œæ¯•")

def split_problems_into_chunks(problems, chunk_size):
    """å°†é—®é¢˜åˆ—è¡¨æŒ‰chunk_sizeæ‹†åˆ†"""
    chunks = []
    for i in range(0, len(problems), chunk_size):
        chunk = problems[i:i+chunk_size]
        chunks.append(chunk)
    return chunks

if __name__ == "__main__":
    # 1. è¯»å–é—®é¢˜æ•°æ®é›†
    json_file = "data/testset_json/optibench.json"
    try:
        with open(json_file, "r", encoding="utf-8") as file:
            problems = json.load(file)
        total_problems = len(problems)
        print(f"âœ… æˆåŠŸè¯»å– {total_problems} ä¸ªé—®é¢˜")
    except Exception as e:
        print(f"âŒ è¯»å–æ•°æ®é›†å¤±è´¥: {str(e)}")
        sys.exit(1)
    
    # 2. æ‹†åˆ†é—®é¢˜ä¸ºchunkï¼ˆæ¯å—100æ¡ï¼‰
    chunks = split_problems_into_chunks(problems, CHUNK_SIZE)
    print(f"ğŸ“Š æ‹†åˆ†åå…± {len(chunks)} ä¸ªchunkï¼Œæ¯ä¸ªchunkæœ€å¤š {CHUNK_SIZE} æ¡é—®é¢˜")
    
    # 3. åˆå§‹åŒ–å¤šè¿›ç¨‹å…±äº«ç»“æœåˆ—è¡¨
    with Manager() as manager:
        results = manager.list()
        start_time = time.time()
        
        # 4. å¯åŠ¨å¤šè¿›ç¨‹å¤„ç†å„chunk
        print(f"ğŸš€ å¯åŠ¨ {PROCESS_MAX_WORKERS} ä¸ªè¿›ç¨‹ï¼Œæ¯ä¸ªè¿›ç¨‹å†… {THREAD_MAX_WORKERS} ä¸ªçº¿ç¨‹...")
        with multiprocessing.Pool(processes=PROCESS_MAX_WORKERS) as process_pool:
            # æäº¤è¿›ç¨‹ä»»åŠ¡ï¼šæ¯ä¸ªè¿›ç¨‹å¤„ç†ä¸€ä¸ªchunk
            process_futures = [
                process_pool.apply_async(process_chunk, args=(chunk, results))
                for chunk in chunks
            ]
            
            # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
            for future in process_futures:
                future.get()  # é˜»å¡ç­‰å¾…è¿›ç¨‹å®Œæˆï¼Œæ•è·è¿›ç¨‹å†…å¼‚å¸¸
        
        # 5. ç»“æœå†™å…¥JSONæ–‡ä»¶
        results_list = list(results)
        with open("results.json", "w", encoding="utf-8") as outfile:
            json.dump(results_list, outfile, ensure_ascii=False, indent=4)
        
        # 6. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        end_time = time.time()
        elapsed_time = end_time - start_time
        print(f"\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
        print(f"æ€»å¤„ç†æ—¶é—´ï¼š{elapsed_time:.2f} ç§’")
        print(f"æ€»é—®é¢˜æ•°ï¼š{total_problems}")
        print(f"æˆåŠŸç”Ÿæˆä»£ç æ•°ï¼š{len([r for r in results_list if 'generated_code' in r])}")
        print(f"å¤±è´¥æ•°ï¼š{len([r for r in results_list if 'error' in r])}")
        print(f"ç»“æœå·²ä¿å­˜åˆ° results.json")